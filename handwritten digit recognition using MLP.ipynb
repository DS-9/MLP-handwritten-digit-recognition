{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the libraries**"
      ],
      "metadata": {
        "id": "lYsWABdE3XzF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1w2xRALv13Uy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sklearn as sk\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Dataset and Input Data**"
      ],
      "metadata": {
        "id": "RbQgFpsX3b-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset  = load_digits()\n",
        "X = dataset['data']\n",
        "Y = dataset['target']"
      ],
      "metadata": {
        "id": "aAB2oZ3P2CZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting the Dataset into Training and Testing Data**"
      ],
      "metadata": {
        "id": "EFjWqq1S3jqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test , Y_train , Y_test = train_test_split( X , Y , test_size=0.2)"
      ],
      "metadata": {
        "id": "bVBc4nxF2E2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the Artificial Neural Network Model using Keras**\n",
        "\n",
        "Neural Network which has 2 layers of 'relu' and the output layer use 'Softmax' for prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "J-zLtUPc3wpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(64,)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "7vkWtPFj2Ja2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compiling the Neural Network**"
      ],
      "metadata": {
        "id": "cnvuJvOo370N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wutD_e_U2N4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**"
      ],
      "metadata": {
        "id": "6iO4jDte4Ag1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, epochs=120, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oofrn2Ba2QuC",
        "outputId": "6e4a693e-3074-4143-bcac-6e0c1a19f57d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.0970e-05 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9750\n",
            "Epoch 2/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.0699e-05 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9750\n",
            "Epoch 3/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.0382e-05 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9750\n",
            "Epoch 4/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 1.0109e-05 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9750\n",
            "Epoch 5/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 9.8265e-06 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9750\n",
            "Epoch 6/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 9.7293e-06 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9750\n",
            "Epoch 7/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 9.5272e-06 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9750\n",
            "Epoch 8/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 8.9704e-06 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9750\n",
            "Epoch 9/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 8.8838e-06 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9750\n",
            "Epoch 10/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 8.6341e-06 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9750\n",
            "Epoch 11/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 8.3652e-06 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9750\n",
            "Epoch 12/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 8.2104e-06 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9750\n",
            "Epoch 13/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 7.9739e-06 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9750\n",
            "Epoch 14/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 7.7227e-06 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9750\n",
            "Epoch 15/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 7.4986e-06 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9750\n",
            "Epoch 16/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 7.3331e-06 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9750\n",
            "Epoch 17/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 7.0676e-06 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9750\n",
            "Epoch 18/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 6.9412e-06 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9750\n",
            "Epoch 19/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 6.9321e-06 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9750\n",
            "Epoch 20/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 6.7989e-06 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9750\n",
            "Epoch 21/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 6.3699e-06 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9750\n",
            "Epoch 22/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 6.3307e-06 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9750\n",
            "Epoch 23/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 6.1167e-06 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9750\n",
            "Epoch 24/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 6.0055e-06 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9750\n",
            "Epoch 25/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.7685e-06 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9750\n",
            "Epoch 26/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 5.6033e-06 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9750\n",
            "Epoch 27/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.4265e-06 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9750\n",
            "Epoch 28/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.4603e-06 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9750\n",
            "Epoch 29/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.1741e-06 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9750\n",
            "Epoch 30/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.0692e-06 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9750\n",
            "Epoch 31/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.9253e-06 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9750\n",
            "Epoch 32/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 4.8807e-06 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9750\n",
            "Epoch 33/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 4.7009e-06 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9750\n",
            "Epoch 34/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.5506e-06 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9750\n",
            "Epoch 35/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.4886e-06 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9750\n",
            "Epoch 36/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 4.3587e-06 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9750\n",
            "Epoch 37/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.2147e-06 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9750\n",
            "Epoch 38/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 4.1789e-06 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9750\n",
            "Epoch 39/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 4.0163e-06 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9750\n",
            "Epoch 40/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.9127e-06 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9750\n",
            "Epoch 41/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.8363e-06 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9750\n",
            "Epoch 42/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.7341e-06 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9750\n",
            "Epoch 43/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.6497e-06 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9750\n",
            "Epoch 44/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.5491e-06 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9750\n",
            "Epoch 45/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.4571e-06 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9750\n",
            "Epoch 46/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.3789e-06 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9750\n",
            "Epoch 47/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.2918e-06 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9750\n",
            "Epoch 48/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.1852e-06 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9750\n",
            "Epoch 49/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.1134e-06 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9750\n",
            "Epoch 50/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.0713e-06 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9750\n",
            "Epoch 51/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.0005e-06 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9750\n",
            "Epoch 52/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.8672e-06 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9750\n",
            "Epoch 53/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.8295e-06 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9750\n",
            "Epoch 54/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 2.7714e-06 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9750\n",
            "Epoch 55/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.6968e-06 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9750\n",
            "Epoch 56/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.6066e-06 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9750\n",
            "Epoch 57/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.5380e-06 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9750\n",
            "Epoch 58/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 2.4681e-06 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9778\n",
            "Epoch 59/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 2.4232e-06 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9750\n",
            "Epoch 60/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 2.3473e-06 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9778\n",
            "Epoch 61/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 2.3009e-06 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9750\n",
            "Epoch 62/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 2.2184e-06 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9778\n",
            "Epoch 63/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 2.1649e-06 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9778\n",
            "Epoch 64/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 2.1079e-06 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9778\n",
            "Epoch 65/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 2.0696e-06 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9778\n",
            "Epoch 66/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 2.0753e-06 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9750\n",
            "Epoch 67/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.9641e-06 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9778\n",
            "Epoch 68/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.8994e-06 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9778\n",
            "Epoch 69/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.8329e-06 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9778\n",
            "Epoch 70/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.7937e-06 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9778\n",
            "Epoch 71/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.7836e-06 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9778\n",
            "Epoch 72/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.7218e-06 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9778\n",
            "Epoch 73/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.6750e-06 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9778\n",
            "Epoch 74/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.6360e-06 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9778\n",
            "Epoch 75/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.5860e-06 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9778\n",
            "Epoch 76/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.5559e-06 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9778\n",
            "Epoch 77/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.5140e-06 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9778\n",
            "Epoch 78/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.4999e-06 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9778\n",
            "Epoch 79/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.4382e-06 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9778\n",
            "Epoch 80/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.4026e-06 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9778\n",
            "Epoch 81/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.3552e-06 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9778\n",
            "Epoch 82/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.3211e-06 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9778\n",
            "Epoch 83/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.2950e-06 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9778\n",
            "Epoch 84/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.2697e-06 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9778\n",
            "Epoch 85/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.2257e-06 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9778\n",
            "Epoch 86/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.1884e-06 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9778\n",
            "Epoch 87/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.1794e-06 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9778\n",
            "Epoch 88/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.1407e-06 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9778\n",
            "Epoch 89/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.1116e-06 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9778\n",
            "Epoch 90/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.0754e-06 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9778\n",
            "Epoch 91/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.0604e-06 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9778\n",
            "Epoch 92/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.0255e-06 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9778\n",
            "Epoch 93/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.0173e-06 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9778\n",
            "Epoch 94/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.7225e-07 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9778\n",
            "Epoch 95/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 9.6371e-07 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9778\n",
            "Epoch 96/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.3384e-07 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9778\n",
            "Epoch 97/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 9.2331e-07 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9778\n",
            "Epoch 98/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 8.6350e-07 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9778\n",
            "Epoch 99/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 8.5114e-07 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9778\n",
            "Epoch 100/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 8.4010e-07 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9778\n",
            "Epoch 101/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 8.1314e-07 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9778\n",
            "Epoch 102/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 8.0285e-07 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9778\n",
            "Epoch 103/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 7.6328e-07 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9778\n",
            "Epoch 104/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 7.5374e-07 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9778\n",
            "Epoch 105/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 7.3425e-07 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9778\n",
            "Epoch 106/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 7.1592e-07 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9778\n",
            "Epoch 107/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 6.9941e-07 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9778\n",
            "Epoch 108/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 6.7610e-07 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9778\n",
            "Epoch 109/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 6.5229e-07 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9778\n",
            "Epoch 110/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 6.5760e-07 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9778\n",
            "Epoch 111/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 6.2342e-07 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9778\n",
            "Epoch 112/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 6.2375e-07 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9778\n",
            "Epoch 113/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 5.8941e-07 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9778\n",
            "Epoch 114/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 5.8302e-07 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9778\n",
            "Epoch 115/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 5.7166e-07 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9778\n",
            "Epoch 116/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 5.4967e-07 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9778\n",
            "Epoch 117/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 5.3258e-07 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9778\n",
            "Epoch 118/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 5.2420e-07 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9778\n",
            "Epoch 119/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.0629e-07 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9778\n",
            "Epoch 120/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.9509e-07 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f738b598670>"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training loss**"
      ],
      "metadata": {
        "id": "UI7z_tfu4JWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXzdDi0b2Vdr",
        "outputId": "15a98957-fa79-488a-be23-d78c0a1f3cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0711e-05 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing loss**"
      ],
      "metadata": {
        "id": "QWYRLJCD4OtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-CmsNC-2Yw5",
        "outputId": "77abf02c-44df-4141-ea7f-911fd86f99d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANN Model implementation using Numpy**"
      ],
      "metadata": {
        "id": "DM-zL9mRC5i2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = model.layers[0].get_weights()[0]               # Layer 0 Weights\n",
        "W2 = model.layers[1].get_weights()[0]               # Layer 1 Weights\n",
        "W3 = model.layers[2].get_weights()[0]               # Layer 2 Weights\n",
        "\n",
        "b1 = model.layers[0].get_weights()[1]               # Layer 0 Biases\n",
        "b2 = model.layers[1].get_weights()[1]               # Layer 1 Biases\n",
        "b3 = model.layers[2].get_weights()[1]               # Layer 2 Biases"
      ],
      "metadata": {
        "id": "CW-gj2eueUiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activation Function**"
      ],
      "metadata": {
        "id": "WKzm5dlh4qa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(A):\n",
        "    return np.maximum(0,A)\n",
        "\n",
        "def softmax(A):\n",
        "  exp_A = np.exp(A)\n",
        "  return exp_A / exp_A.sum()"
      ],
      "metadata": {
        "id": "l299NXqRejTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Forward Propagation**"
      ],
      "metadata": {
        "id": "AQJfEVOX4tvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X):\n",
        "  Z1 = np.dot(X , W1) + b1\n",
        "  A1 = relu(Z1)\n",
        "  Z2 = np.dot(A1 , W2) + b2\n",
        "  A2 = relu(Z2)\n",
        "  Z3 = np.dot(A2 , W3) + b3\n",
        "  A3 = softmax(Z3)\n",
        "  return A3"
      ],
      "metadata": {
        "id": "LKSsZuBfenRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating Accuracy of the model**"
      ],
      "metadata": {
        "id": "jvx5e5L14wyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(predictions , labels):\n",
        "  return np.mean(predictions.argmax(axis=1) == labels)"
      ],
      "metadata": {
        "id": "tc855ruHezJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrieving the Prediction**"
      ],
      "metadata": {
        "id": "TrvP_uuF41tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = forward_propagation(X_test)\n",
        "\n",
        "acc = accuracy(predictions, Y_test)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm32KpM6e7-y",
        "outputId": "918abec5-df74-410a-9e27-eed05719180e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting the images and comparing the performance of Keras and Numpy model**"
      ],
      "metadata": {
        "id": "YiHWPaDq46Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"My ANN Model's Prediction\")\n",
        "\n",
        "fig, ax = plt.subplots(2, 5, figsize=(8, 4))\n",
        "\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    imgg = X_test[i].reshape(8, 8)\n",
        "    axi.imshow(imgg, cmap='binary')\n",
        "    axi.set(xticks=[], yticks=[])\n",
        "    axi.set_xlabel(predictions[i].argmax(), color='green')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Keras implemented ANN Model's Prediction\")\n",
        "# Keras model plot\n",
        "fig, axs = plt.subplots(2, 5 ,figsize=(8, 4))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i in range(10):\n",
        "    img = X_test[i].reshape(8, 8)\n",
        "    axs[i].imshow(img, cmap='binary')\n",
        "    axs[i].set_title(np.argmax(y_pred[i]),  color='blue')\n",
        "    axs[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "8Yby-fZIiyEv",
        "outputId": "8304a555-d244-4aa9-d0d7-d0d668a8124c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My ANN Model's Prediction\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 2ms/step\n",
            "Keras implemented ANN Model's Prediction\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}